{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d62e5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Basmala Kamal\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"RJT1990/GeneralThoughtArchive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abf56b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f819da52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   question_id                                       question_url  \\\n",
      "0       806845  https://gr.inc/question/how-do-the-neural-resp...   \n",
      "1      1730456  https://gr.inc/question/lets-consider-some-arr...   \n",
      "2      3236068  https://gr.inc/question/what-are-the-primary-c...   \n",
      "3      1717140  https://gr.inc/question/consider-a-football-to...   \n",
      "4      3235833  https://gr.inc/question/given-the-context-of-h...   \n",
      "\n",
      "                                            question  \\\n",
      "0     How do the neural respiratory centers operate?   \n",
      "1  Let's consider some array A. The following alg...   \n",
      "2  What are the primary criticisms Aristotle rais...   \n",
      "3  Consider a football tournament where n teams p...   \n",
      "4  Given the context of Heidegger's philosophy, p...   \n",
      "\n",
      "                                    reference_answer prev_messages  \\\n",
      "0  In the medulla oblongata, respiratory neurons ...          None   \n",
      "1                                               None          None   \n",
      "2  Aristotle's criticisms of Plato's theory of fo...          None   \n",
      "3                                               None          None   \n",
      "4  The anticipation of death as a possibility is ...          None   \n",
      "\n",
      "             model_name                                       model_answer  \\\n",
      "0  DeepSeek/DeepSeek-R1  The neural respiratory centers operate through...   \n",
      "1  DeepSeek/DeepSeek-R1  ```python\\nimport sys\\nfrom collections import...   \n",
      "2  DeepSeek/DeepSeek-R1  Aristotle's criticisms of Plato's Theory of Fo...   \n",
      "3  DeepSeek/DeepSeek-R1  ```python\\nfrom collections import Counter\\n\\n...   \n",
      "4  DeepSeek/DeepSeek-R1  In Heidegger's philosophy, particularly throug...   \n",
      "\n",
      "                                     model_reasoning               task  \\\n",
      "0  Okay, so I need to figure out how the neural r...      Human Biology   \n",
      "1  Okay, let's see. I need to find the maximum po...  Greedy algorithms   \n",
      "2  Okay, so I need to figure out what Aristotle's...         Philosophy   \n",
      "3  Okay, let's see. I need to solve this programm...    Complete search   \n",
      "4  Okay, so I need to explain how anticipating de...         Philosophy   \n",
      "\n",
      "  question_license         question_source  community_answer_score  \\\n",
      "0              MIT            General/VNet                       0   \n",
      "1       Apache-2.0               BAAI/TACO                       0   \n",
      "2  CC-BY-NC-SA-4.0  Meta/natural_reasoning                       0   \n",
      "3       Apache-2.0               BAAI/TACO                       0   \n",
      "4  CC-BY-NC-SA-4.0  Meta/natural_reasoning                       0   \n",
      "\n",
      "   community_question_score  verifier_score  \n",
      "0                         0             NaN  \n",
      "1                         0             NaN  \n",
      "2                         0             NaN  \n",
      "3                         0             NaN  \n",
      "4                         0             NaN  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(ds['train'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "791f2aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(430788, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "776da16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 430788 entries, 0 to 430787\n",
      "Data columns (total 14 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   question_id               430788 non-null  int64  \n",
      " 1   question_url              430788 non-null  object \n",
      " 2   question                  430788 non-null  object \n",
      " 3   reference_answer          306178 non-null  object \n",
      " 4   prev_messages             102234 non-null  object \n",
      " 5   model_name                430788 non-null  object \n",
      " 6   model_answer              430788 non-null  object \n",
      " 7   model_reasoning           428151 non-null  object \n",
      " 8   task                      430788 non-null  object \n",
      " 9   question_license          429474 non-null  object \n",
      " 10  question_source           430788 non-null  object \n",
      " 11  community_answer_score    430788 non-null  int64  \n",
      " 12  community_question_score  430788 non-null  int64  \n",
      " 13  verifier_score            338377 non-null  float64\n",
      "dtypes: float64(1), int64(3), object(10)\n",
      "memory usage: 46.0+ MB\n",
      "None\n",
      "\n",
      "Column names:\n",
      "['question_id', 'question_url', 'question', 'reference_answer', 'prev_messages', 'model_name', 'model_answer', 'model_reasoning', 'task', 'question_license', 'question_source', 'community_answer_score', 'community_question_score', 'verifier_score']\n"
     ]
    }
   ],
   "source": [
    "# Check data types, non-null counts, memory usage\n",
    "print(df.info())\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed0b8926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n",
      "question_id                      0\n",
      "question_url                     0\n",
      "question                         0\n",
      "reference_answer            124610\n",
      "prev_messages               328554\n",
      "model_name                       0\n",
      "model_answer                     0\n",
      "model_reasoning               2637\n",
      "task                             0\n",
      "question_license              1314\n",
      "question_source                  0\n",
      "community_answer_score           0\n",
      "community_question_score         0\n",
      "verifier_score               92411\n",
      "dtype: int64\n",
      "\n",
      "Missing value percentages:\n",
      "question_id                  0.000000\n",
      "question_url                 0.000000\n",
      "question                     0.000000\n",
      "reference_answer            28.926061\n",
      "prev_messages               76.268141\n",
      "model_name                   0.000000\n",
      "model_answer                 0.000000\n",
      "model_reasoning              0.612134\n",
      "task                         0.000000\n",
      "question_license             0.305022\n",
      "question_source              0.000000\n",
      "community_answer_score       0.000000\n",
      "community_question_score     0.000000\n",
      "verifier_score              21.451619\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Missing value analysis\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nMissing value percentages:\")\n",
    "print((df.isnull().sum() / len(df)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "722b1bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of model_reasoning (first 3 rows):\n",
      "\n",
      "--- Row 0 ---\n",
      "Okay, so I need to figure out how the neural respiratory centers work. Let me start by recalling what I know about breathing and the nervous system. I remember that breathing is controlled by parts of the brain, right? There's the medulla and the pons mentioned in some biology classes. But wait, how exactly do they work together?\n",
      "\n",
      "First, there's the medulla oblongata. I think that's the primary control center. It has groups of neurons called the dorsal respiratory group and the ventral respirato\n",
      "\n",
      "--- Row 1 ---\n",
      "Okay, let's see. I need to find the maximum possible force of an array after reordering some elements. The force is calculated by summing the squares of the lengths of consecutive equal elements. So the problem is, given the array generated by a specific recurrence relation, how can I rearrange its elements to maximize this sum of squares?\n",
      "\n",
      "Hmm. The key here is that the optimal arrangement groups as many same elements as possible into the largest possible blocks. Because when you square the leng\n",
      "\n",
      "--- Row 2 ---\n",
      "Okay, so I need to figure out what Aristotle's main criticisms were against Plato's Theory of Forms and how these criticisms show their different views on metaphysics, reality, and knowledge. Let me start by recalling what I know about Plato's Theory of Forms. From what I remember, Plato believed that non-material abstract forms (or ideas) are the most accurate reality. These forms are perfect, unchanging, and exist in a separate realm from the physical world we experience. For example, there's \n"
     ]
    }
   ],
   "source": [
    "# Check if critical text fields are populated\n",
    "print(\"\\nSample of model_reasoning (first 3 rows):\")\n",
    "for i in range(min(3, len(df))):\n",
    "    print(f\"\\n--- Row {i} ---\")\n",
    "    print(df.iloc[i]['model_reasoning'][:500])  # First 500 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c211825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model reasoning missing:\n",
      "2637\n",
      "\n",
      "Dataset size after removing missing reasoning: (428151, 14)\n"
     ]
    }
   ],
   "source": [
    "# Check reasoning field completeness\n",
    "print(\"\\nModel reasoning missing:\")\n",
    "print(df['model_reasoning'].isnull().sum())\n",
    "\n",
    "# Drop rows without reasoning (can't extract features)\n",
    "df_clean = df[df['model_reasoning'].notna()].copy()\n",
    "print(f\"\\nDataset size after removing missing reasoning: {df_clean.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "357fbb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prev_messages present:\n",
      "102234\n",
      "\n",
      "Dataset size after keeping only rows with null prev_messages: (328554, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPrev_messages present:\")\n",
    "print(df['prev_messages'].notna().sum())\n",
    "\n",
    "# Keep only rows where prev_messages is null\n",
    "df_clean = df[df['prev_messages'].isnull()].copy()\n",
    "\n",
    "print(f\"\\nDataset size after keeping only rows with null prev_messages: {df_clean.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7bd1c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Token count\n",
    "df_clean['feat_token_count'] = df_clean['model_answer'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Sentence count (periods, exclamation, question marks)\n",
    "df_clean['feat_sentence_count'] = df_clean['model_answer'].apply(\n",
    "    lambda x: len(re.findall(r'[.!?]+', str(x)))\n",
    ")\n",
    "\n",
    "# Step markers (1., 2., Step 1, etc.)\n",
    "df_clean['feat_step_markers'] = df_clean['model_answer'].apply(\n",
    "    lambda x: len(re.findall(r'\\b(?:step\\s*\\d+|^\\d+\\.|\\n\\d+\\.)', str(x).lower()))\n",
    ")\n",
    "\n",
    "# Average sentence length\n",
    "df_clean['feat_avg_sentence_len'] = (df_clean['feat_token_count'] / \n",
    "                                      (df_clean['feat_sentence_count'] + 1))\n",
    "\n",
    "# Max sentence length (split by periods, find longest)\n",
    "def max_sent_len(text):\n",
    "    sentences = re.split(r'[.!?]+', str(text))\n",
    "    if not sentences:\n",
    "        return 0\n",
    "    return max(len(s.split()) for s in sentences)\n",
    "\n",
    "df_clean['feat_max_sentence_len'] = df_clean['model_answer'].apply(max_sent_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f256167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LaTeX operator counts (sum, frac, etc.)\n",
    "df_clean['feat_latex_operators'] = df_clean['model_answer'].apply(\n",
    "    lambda x: len(re.findall(r'\\\\(?:frac|sum|int|times|div|sqrt)', str(x)))\n",
    ")\n",
    "\n",
    "# Digit ratio (proportion of characters that are digits)\n",
    "df_clean['feat_digit_ratio'] = df_clean['model_answer'].apply(\n",
    "    lambda x: sum(c.isdigit() for c in str(x)) / (len(str(x)) + 1)\n",
    ")\n",
    "\n",
    "# Equation sign density (=, +, -, *, /)\n",
    "df_clean['feat_equation_signs'] = df_clean['model_answer'].apply(\n",
    "    lambda x: len(re.findall(r'[=+\\-*/]', str(x)))\n",
    ")\n",
    "\n",
    "# Operator variety (unique math operators)\n",
    "def operator_variety(text):\n",
    "    operators = set(re.findall(r'[+\\-*/=<>≤≥]', str(text)))\n",
    "    return len(operators)\n",
    "\n",
    "df_clean['feat_operator_variety'] = df_clean['model_answer'].apply(operator_variety)\n",
    "\n",
    "# Code block presence (``````)\n",
    "df_clean['feat_has_code_block'] = df_clean['model_answer'].apply(\n",
    "    lambda x: 1 if '```' in str(x) else 0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0231516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connective words (because, therefore, thus, so, hence)\n",
    "logic_connectives = ['because', 'therefore', 'thus', 'hence', 'since', 'consequently']\n",
    "df_clean['feat_logic_connectives'] = df_clean['model_answer'].apply(\n",
    "    lambda x: sum(str(x).lower().count(word) for word in logic_connectives)\n",
    ")\n",
    "\n",
    "# Self-correction markers (wait, actually, correction, mistake)\n",
    "correction_words = ['wait', 'actually', 'correction', 'mistake', 'error', 'wrong']\n",
    "df_clean['feat_self_corrections'] = df_clean['model_answer'].apply(\n",
    "    lambda x: sum(str(x).lower().count(word) for word in correction_words)\n",
    ")\n",
    "\n",
    "# Contradiction indicators (but, however near numbers)\n",
    "def contradictions_near_numbers(text):\n",
    "    text_lower = str(text).lower()\n",
    "    # Find \"but\" or \"however\" within 10 words of a number\n",
    "    matches = re.findall(r'(?:\\d+.{0,50}(?:but|however))|(?:(?:but|however).{0,50}\\d+)', text_lower)\n",
    "    return len(matches)\n",
    "\n",
    "df_clean['feat_contradiction_markers'] = df_clean['model_answer'].apply(contradictions_near_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1433e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question-to-reasoning overlap (Jaccard similarity)\n",
    "def jaccard_similarity(text1, text2):\n",
    "    set1 = set(str(text1).lower().split())\n",
    "    set2 = set(str(text2).lower().split())\n",
    "    if not set1 or not set2:\n",
    "        return 0\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "df_clean['feat_question_overlap'] = df_clean.apply(\n",
    "    lambda row: jaccard_similarity(row['question'], row['model_reasoning']), axis=1\n",
    ")\n",
    "\n",
    "# Extra numbers (numbers in reasoning not in question)\n",
    "def extract_numbers(text):\n",
    "    return set(re.findall(r'\\d+\\.?\\d*', str(text)))\n",
    "\n",
    "df_clean['feat_extra_numbers'] = df_clean.apply(\n",
    "    lambda row: len(extract_numbers(row['model_reasoning']) - extract_numbers(row['question'])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Final answer formatting (presence of \"Answer:\", \"Final answer:\", etc.)\n",
    "df_clean['feat_has_answer_marker'] = df_clean['model_reasoning'].apply(\n",
    "    lambda x: 1 if re.search(r'\\b(?:answer|conclusion|result):', str(x).lower()) else 0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e62c2be",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     37\u001b[39m     unique_trigrams = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(trigrams))\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m1\u001b[39m - (unique_trigrams / \u001b[38;5;28mlen\u001b[39m(trigrams))\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m df_clean[\u001b[33m'\u001b[39m\u001b[33mfeat_repeated_trigrams\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf_clean\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel_answer\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepeated_trigrams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\series.py:4924\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4790\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4791\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4796\u001b[39m     **kwargs,\n\u001b[32m   4797\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4799\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4800\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4915\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4916\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4922\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\apply.py:1427\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1426\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\apply.py:1507\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1505\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1506\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1512\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\base.py:921\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mrepeated_trigrams\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     27\u001b[39m df_clean[\u001b[33m'\u001b[39m\u001b[33mfeat_parentheses_balanced\u001b[39m\u001b[33m'\u001b[39m] = df_clean[\u001b[33m'\u001b[39m\u001b[33mmodel_answer\u001b[39m\u001b[33m'\u001b[39m].apply(parentheses_balanced)\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Repeated n-gram rate (3-grams that appear more than once)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrepeated_trigrams\u001b[39m(text):\n\u001b[32m     31\u001b[39m     words = \u001b[38;5;28mstr\u001b[39m(text).lower().split()\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(words) < \u001b[32m3\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Type-token ratio (unique words / total words)\n",
    "def type_token_ratio(text):\n",
    "    words = str(text).lower().split()\n",
    "    if not words:\n",
    "        return 0\n",
    "    return len(set(words)) / len(words)\n",
    "\n",
    "df_clean['feat_type_token_ratio'] = df_clean['model_answer'].apply(type_token_ratio)\n",
    "\n",
    "# Punctuation density\n",
    "df_clean['feat_punctuation_density'] = df_clean['model_answer'].apply(\n",
    "    lambda x: len(re.findall(r'[.,;:!?]', str(x))) / (len(str(x)) + 1)\n",
    ")\n",
    "\n",
    "# Parentheses balance (are they properly matched?)\n",
    "def parentheses_balanced(text):\n",
    "    count = 0\n",
    "    for char in str(text):\n",
    "        if char == '(':\n",
    "            count += 1\n",
    "        elif char == ')':\n",
    "            count -= 1\n",
    "        if count < 0:\n",
    "            return 0  # Unbalanced\n",
    "    return 1 if count == 0 else 0\n",
    "\n",
    "df_clean['feat_parentheses_balanced'] = df_clean['model_answer'].apply(parentheses_balanced)\n",
    "\n",
    "# Repeated n-gram rate (3-grams that appear more than once)\n",
    "def repeated_trigrams(text):\n",
    "    words = str(text).lower().split()\n",
    "    if len(words) < 3:\n",
    "        return 0\n",
    "    trigrams = [' '.join(words[i:i+3]) for i in range(len(words)-2)]\n",
    "    if not trigrams:\n",
    "        return 0\n",
    "    unique_trigrams = len(set(trigrams))\n",
    "    return 1 - (unique_trigrams / len(trigrams))\n",
    "\n",
    "df_clean['feat_repeated_trigrams'] = df_clean['model_answer'].apply(repeated_trigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode model_name (or use label encoding)\n",
    "# Option A: One-hot (creates multiple binary columns)\n",
    "model_dummies = pd.get_dummies(df_clean['model_name'], prefix='model')\n",
    "df_clean = pd.concat([df_clean, model_dummies], axis=1)\n",
    "\n",
    "# Option B: Label encoding (single numeric column) - simpler for initial exploration\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_model = LabelEncoder()\n",
    "df_clean['model_name_encoded'] = le_model.fit_transform(df_clean['model_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2694b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Select only numeric feature columns\n",
    "feature_cols = [col for col in df_clean.columns if col.startswith('feat_')]\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nFeature Summary Statistics:\")\n",
    "print(df_clean[feature_cols].describe())\n",
    "\n",
    "# Correlation with label\n",
    "print(\"\\nCorrelation with label:\")\n",
    "correlations = df_clean[feature_cols + ['label']].corr()['label'].sort_values(ascending=False)\n",
    "print(correlations)\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df_clean[feature_cols].corr(), annot=False, cmap='coolwarm')\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_correlation_heatmap.png')\n",
    "plt.show()\n",
    "\n",
    "# Distribution plots for top correlated features\n",
    "top_features = correlations.abs().sort_values(ascending=False)[1:6].index\n",
    "for feat in top_features:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    df_clean[feat].hist(bins=50)\n",
    "    plt.xlabel(feat)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of {feat}')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    df_clean.boxplot(column=feat, by='label')\n",
    "    plt.xlabel('Label (0=Incorrect, 1=Correct)')\n",
    "    plt.ylabel(feat)\n",
    "    plt.title(f'{feat} by Correctness')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{feat}_analysis.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fead56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers using IQR method\n",
    "for feat in feature_cols:\n",
    "    Q1 = df_clean[feat].quantile(0.25)\n",
    "    Q3 = df_clean[feat].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outlier_count = ((df_clean[feat] < (Q1 - 1.5 * IQR)) | \n",
    "                     (df_clean[feat] > (Q3 + 1.5 * IQR))).sum()\n",
    "    print(f\"{feat}: {outlier_count} outliers ({outlier_count/len(df_clean)*100:.2f}%)\")\n",
    "\n",
    "# Standardization (z-score)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_clean[feature_cols] = scaler.fit_transform(df_clean[feature_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c112a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group split by model_name (as specified in proposal)\n",
    "unique_models = df_clean['model_name'].unique()\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(unique_models)\n",
    "\n",
    "n_models = len(unique_models)\n",
    "train_models = unique_models[:int(0.7 * n_models)]\n",
    "val_models = unique_models[int(0.7 * n_models):int(0.85 * n_models)]\n",
    "test_models = unique_models[int(0.85 * n_models):]\n",
    "\n",
    "train_df = df_clean[df_clean['model_name'].isin(train_models)]\n",
    "val_df = df_clean[df_clean['model_name'].isin(val_models)]\n",
    "test_df = df_clean[df_clean['model_name'].isin(test_models)]\n",
    "\n",
    "print(f\"\\nTrain: {len(train_df)} ({len(train_df)/len(df_clean)*100:.1f}%)\")\n",
    "print(f\"Val: {len(val_df)} ({len(val_df)/len(df_clean)*100:.1f}%)\")\n",
    "print(f\"Test: {len(test_df)} ({len(test_df)/len(df_clean)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f18ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed datasets\n",
    "train_df.to_csv('train_dataset.csv', index=False)\n",
    "val_df.to_csv('val_dataset.csv', index=False)\n",
    "test_df.to_csv('test_dataset.csv', index=False)\n",
    "\n",
    "# Also save a combined version\n",
    "df_clean.to_csv('full_cleaned_dataset.csv', index=False)\n",
    "\n",
    "print(\"\\nFinal dataset characteristics:\")\n",
    "print(f\"Total samples: {len(df_clean)}\")\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"Label distribution: {df_clean['label'].value_counts(normalize=True).to_dict()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
